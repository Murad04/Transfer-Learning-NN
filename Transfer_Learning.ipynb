{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPPniiF3zbBR5LiF6t+RhXv"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch as T\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.transforms import ToTensor\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "import torchvision.datasets as datasets"
      ],
      "metadata": {
        "id": "DhdObrDfKiET"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_parameter_requires_grad(model,extracting):\n",
        "  if extracting:\n",
        "    for param in model.parameters():\n",
        "      param.requires_grad=False\n",
        "\n",
        "def train_model(model,data_loaders,criterion,optimizer,epochs=25):\n",
        "  for epoch in range(epochs):\n",
        "    print('Epoch %d / %d' %(epoch,epochs-1))\n",
        "    print('-'*15)\n",
        "\n",
        "    for phase in ['train','val']:\n",
        "      if phase == 'train':\n",
        "        model.train()\n",
        "      else:\n",
        "        model.eval()\n",
        "\n",
        "      running_loss=0.0\n",
        "      correct=0\n",
        "\n",
        "      for inputs,labels in data_loaders[phase]:\n",
        "        inputs=inputs.to(device)\n",
        "        labels=labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        with T.set_grad_enabled(phase=='train'):\n",
        "          outputs=model(inputs)\n",
        "          loss=criterion(outputs,labels)\n",
        "\n",
        "          _,preds=T.max(outputs,1)\n",
        "\n",
        "          if phase=='train':\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        running_loss+=loss.item()*inputs.size(0)\n",
        "        correct+=T.sum(preds==labels.data)\n",
        "\n",
        "    epoch_loss=running_loss/len(data_loaders[phase].dataset)\n",
        "    epoch_acc=correct.double()/len(data_loaders[phase].dataset)\n",
        "\n",
        "    print('{} Loss: {.4f} Acc: {.4f}'.format(phase,epoch_loss,epoch_acc))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  root_dir='hymenoptera_data/hymenoptera_data/'\n",
        "\n",
        "  image_transforms={\n",
        "      \"train\":transforms.Compose([transforms.RandomRotation((-270,270)),\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                                                       std=[0.229,0.224,0.225])]),\n",
        "      'val':transforms.Compose([transforms.RandomRotation((-270,270)),\n",
        "                                  transforms.Resize((224,224)),\n",
        "                                  transforms.ToTensor(),\n",
        "                                  transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                                                       std=[0.229,0.224,0.225])])\n",
        "  }\n",
        "  data_generator = {k: datasets.ImageFolder(os.path.join(root_dir, k),\n",
        "                                      image_transforms[k]) for k in ['train', 'val']}\n",
        "\n",
        "  data_loader={k:T.utils.data.DataLoader(data_generator[k],batch_size=2,shuffle=True,num_workers=4)\n",
        "              for k in ['train','val']}\n",
        "\n",
        "  device=T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
        "  model=models.resnet18(pretrained=True)\n",
        "\n",
        "\n",
        "  set_parameter_requires_grad(model,True)\n",
        "\n",
        "  num_features=model.fc.in_features\n",
        "  modelfc=nn.Linear(num_features,2)\n",
        "  model.to(device)\n",
        "\n",
        "  criterion=nn.CrossEntropyLoss()\n",
        "  optimizer=optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "  params_to_update=[]\n",
        "  for name,param in model.named_parameters():\n",
        "    if param.requires_grad is True:\n",
        "      params_to_update.append(param)\n",
        "      print('\\t', name)\n",
        "\n",
        "  train_model(model, data_loader, criterion,optimizer)\n",
        ""
      ],
      "metadata": {
        "id": "G85bULSgqBjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "03SmW4pS1Q5D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}